{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "papermill": {
     "duration": 3.250255,
     "end_time": "2025-02-20T05:12:56.861553",
     "exception": false,
     "start_time": "2025-02-20T05:12:53.611298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import log_loss, brier_score_loss, mean_squared_error, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.base import clone\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "papermill": {
     "duration": 0.010506,
     "end_time": "2025-02-20T05:12:56.880965",
     "exception": false,
     "start_time": "2025-02-20T05:12:56.870459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = '/kaggle/input/march-machine-learning-mania-2025/**'\n",
    "data_dir ='data/**'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "papermill": {
     "duration": 0.180698,
     "end_time": "2025-02-20T05:12:57.065231",
     "exception": false,
     "start_time": "2025-02-20T05:12:56.884533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TournamentPredictor:\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_path = data_dir\n",
    "        self.data = None\n",
    "        self.teams = None\n",
    "        self.seeds = None\n",
    "        self.games = None\n",
    "        self.sub = None\n",
    "        self.gb = None\n",
    "        self.col = None\n",
    "        self.imputer = SimpleImputer(strategy='mean')\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def load_data(self):\n",
    "        files = glob.glob(self.data_path)\n",
    "        self.data = {p.split('/')[-1].split('.')[0]: pd.read_csv(p, encoding='latin-1') for p in files}\n",
    "\n",
    "        teams = pd.concat([self.data['MTeams'], self.data['WTeams']])\n",
    "        teams_spelling = pd.concat([self.data['MTeamSpellings'], self.data['WTeamSpellings']])\n",
    "        teams_spelling = teams_spelling.groupby(by='TeamID', as_index=False)['TeamNameSpelling'].count()\n",
    "        teams_spelling.columns = ['TeamID', 'TeamNameCount']\n",
    "        self.teams = pd.merge(teams, teams_spelling, how='left', on=['TeamID'])\n",
    "\n",
    "        season_cresults = pd.concat([self.data['MRegularSeasonCompactResults'], self.data['WRegularSeasonCompactResults']])\n",
    "        season_dresults = pd.concat([self.data['MRegularSeasonDetailedResults'], self.data['WRegularSeasonDetailedResults']])\n",
    "        tourney_cresults = pd.concat([self.data['MNCAATourneyCompactResults'], self.data['WNCAATourneyCompactResults']])\n",
    "    \n",
    "        tourney_dresults = pd.concat([self.data['MNCAATourneyDetailedResults'], self.data['WNCAATourneyDetailedResults']])\n",
    "\n",
    "        seeds_df = pd.concat([self.data['MNCAATourneySeeds'], self.data['WNCAATourneySeeds']])\n",
    "        self.seeds = {'_'.join(map(str, [int(k1), k2])): int(v[1:3]) for k1, v, k2 in seeds_df[['Season', 'Seed', 'TeamID']].values}\n",
    "\n",
    "        self.sub = self.data['SampleSubmissionStage1']\n",
    "\n",
    "        season_cresults['ST'] = 'S'\n",
    "        season_dresults['ST'] = 'S'\n",
    "        tourney_cresults['ST'] = 'T'\n",
    "        tourney_dresults['ST'] = 'T'\n",
    "\n",
    "        self.games = pd.concat((season_dresults, tourney_dresults), axis=0, ignore_index=True)\n",
    "        #restrict to only tournament data (faster & better)\n",
    "        self.games = self.games[self.games['ST'] == 'T']\n",
    "        self.games['WLoc'] = self.games['WLoc'].map({'A': 1, 'H': 2, 'N': 3})\n",
    "\n",
    "        self.games['ID'] = self.games.apply(lambda r: '_'.join(map(str, [r['Season']] + sorted([r['WTeamID'], r['LTeamID']]))), axis=1)\n",
    "        self.games['IDTeams'] = self.games.apply(lambda r: '_'.join(map(str, sorted([r['WTeamID'], r['LTeamID']]))), axis=1)\n",
    "        self.games['Team1'] = self.games.apply(lambda r: sorted([r['WTeamID'], r['LTeamID']])[0], axis=1)\n",
    "        self.games['Team2'] = self.games.apply(lambda r: sorted([r['WTeamID'], r['LTeamID']])[1], axis=1)\n",
    "        self.games['IDTeam1'] = self.games.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\n",
    "        self.games['IDTeam2'] = self.games.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n",
    "        self.games['Team1Seed'] = self.games['IDTeam1'].map(self.seeds).fillna(0)\n",
    "        self.games['Team2Seed'] = self.games['IDTeam2'].map(self.seeds).fillna(0)\n",
    "        self.games['ScoreDiff'] = self.games['WScore'] - self.games['LScore']\n",
    "        # team 1 won == (pred = 1)\n",
    "        self.games['Pred'] = self.games.apply(lambda r: 1.0 if sorted([r['WTeamID'], r['LTeamID']])[0] == r['WTeamID'] else 0.0, axis=1)\n",
    "        self.games['ScoreDiffNorm'] = self.games.apply(lambda r: r['ScoreDiff'] * -1 if r['Pred'] == 0.0 else r['ScoreDiff'], axis=1)\n",
    "        self.games['SeedDiff'] = self.games['Team1Seed'] - self.games['Team2Seed']\n",
    "\n",
    "\n",
    "        team1 = ['FGM1', 'FGA1', 'FGM31', 'FGA31', 'FTM1', 'FTA1', 'OR1', 'DR1', 'Ast1', 'TO1', 'Stl1', 'Blk1', 'PF1']\n",
    "        team2 = ['FGM2', 'FGA2', 'FGM32', 'FGA32', 'FTM2', 'FTA2', 'OR2', 'DR2', 'Ast2', 'TO2', 'Stl2', 'Blk2', 'PF2']\n",
    "        self.games[team1 + team2] = self.games.apply(self.sortStatsByWinTeam, axis=1, result_type='expand')\n",
    "\n",
    "\n",
    "        # momentum as feature (win loss streaks / wins in a row, wins in last 5 games)\n",
    "        # we would use the latest data for a team to calculate the momentum\n",
    "        self.create_features(self.games)\n",
    "\n",
    "        \n",
    "        c_score_col = ['NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF']\n",
    "        self.games.drop(columns=c_score_col, inplace=True)\n",
    "\n",
    "        c_score_col = team1 + team2\n",
    "        c_score_agg = ['sum', 'mean', 'median', 'max', 'min', 'std', 'skew', 'nunique']\n",
    "        self.gb = self.games.groupby(by=['IDTeams']).agg({k: c_score_agg for k in c_score_col}).reset_index()\n",
    "\n",
    "        self.gb.columns = [''.join(c) + '_c_score' for c in self.gb.columns]\n",
    "\n",
    "        \n",
    "\n",
    "        self.sub['WLoc'] = 3\n",
    "        self.sub['Season'] = self.sub['ID'].map(lambda x: x.split('_')[0]).astype(int)\n",
    "        self.sub['Team1'] = self.sub['ID'].map(lambda x: x.split('_')[1])\n",
    "        self.sub['Team2'] = self.sub['ID'].map(lambda x: x.split('_')[2])\n",
    "        self.sub['IDTeams'] = self.sub.apply(lambda r: '_'.join(map(str, [r['Team1'], r['Team2']])), axis=1)\n",
    "        self.sub['IDTeam1'] = self.sub.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\n",
    "        self.sub['IDTeam2'] = self.sub.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n",
    "        self.sub['Team1Seed'] = self.sub['IDTeam1'].map(self.seeds).fillna(0)\n",
    "        self.sub['Team2Seed'] = self.sub['IDTeam2'].map(self.seeds).fillna(0)\n",
    "        self.sub['SeedDiff'] = self.sub['Team1Seed'] - self.sub['Team2Seed']\n",
    "        self.sub = self.sub.fillna(-1)\n",
    "\n",
    "        self.games = pd.merge(self.games, self.gb, how='left', left_on='IDTeams', right_on='IDTeams_c_score')\n",
    "        self.sub = pd.merge(self.sub, self.gb, how='left', left_on='IDTeams', right_on='IDTeams_c_score')\n",
    "\n",
    "        exclude_cols = ['ID', 'DayNum', 'ST', 'Team1', 'Team2', 'IDTeams', 'IDTeam1', 'IDTeam2', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'NumOT', 'Pred', 'ScoreDiff', 'ScoreDiffNorm', 'WLoc','IDTeams_c_score'] + c_score_col\n",
    "        self.col = [c for c in self.games.columns if c not in exclude_cols]\n",
    "        print(\"Data loading and preprocessing completed.\")\n",
    "\n",
    "    def sortStatsByWinTeam(self, row):\n",
    "        winF = ['WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF']\n",
    "        loseF = ['LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF']\n",
    "        if row['IDTeam1'] == row['WTeamID']:\n",
    "            return row[winF + loseF]\n",
    "        else:\n",
    "            return row[loseF + winF]\n",
    "        \n",
    "\n",
    "    def create_features(self, df):\n",
    "        # 1. Effective Field Goal Percentage (EFG%)\n",
    "        def calculate_efg(fgm, fgm3, fga):\n",
    "            if fga == 0:\n",
    "                return 0.0  # Avoid division by zero\n",
    "            return (fgm + 0.5 * fgm3) / fga\n",
    "        \n",
    "        def calculate_perc(made, att):\n",
    "            if att == 0:\n",
    "                return 0.0  # Avoid division by zero\n",
    "            return np.round(made / att, 3)\n",
    "        \n",
    "        df['Team1_EFG'] = df.apply(lambda row: calculate_efg(row['FGM1'], row['FGM31'], row['FGA1']), axis=1)\n",
    "        df['Team2_EFG'] = df.apply(lambda row: calculate_efg(row['FGM2'], row['FGM32'], row['FGA2']), axis=1)\n",
    "        df['EFG_Diff'] = df['Team1_EFG'] - df['Team2_EFG']\n",
    "\n",
    "        df['Team1_FGP'] = df.apply(lambda row: calculate_perc(row['FGM1'], row['FGA1']), axis=1)\n",
    "        df['Team2_FGP'] = df.apply(lambda row: calculate_perc(row['FGM2'], row['FGA2']), axis=1)\n",
    "        df['FGP_Diff'] = df['Team1_FGP'] - df['Team2_FGP']\n",
    "        \n",
    "        df['Team1_FGP3'] = df.apply(lambda row: calculate_perc(row['FGM31'], row['FGA31']), axis=1)\n",
    "        df['Team2_FGP3'] = df.apply(lambda row: calculate_perc(row['FGM32'], row['FGA32']), axis=1)\n",
    "        df['FGP3_Diff'] = df['Team1_FGP3'] - df['Team2_FGP3']\n",
    "\n",
    "        # 3. WLoc Feature transformation\n",
    "        # Replace WLoc values with numerical representations\n",
    "        df['WLoc'] = df['WLoc'].replace({'H': 1, 'A': -1, 'N': 0})\n",
    "\n",
    "        # Create features for Team 1 and Team 2 based on WLoc\n",
    "        df['Team1_Home'] = np.where((df['IDTeam1'] == df['WTeamID']) & (df['WLoc'] == 1), 1,\n",
    "                                np.where((df['IDTeam1'] == df['LTeamID']) & (df['WLoc'] == -1), 1, 0))\n",
    "        df['Team2_Home'] = np.where((df['IDTeam2'] == df['WTeamID']) & (df['WLoc'] == 1), 1,\n",
    "                                np.where((df['IDTeam2'] == df['LTeamID']) & (df['WLoc'] == -1), 1, 0))\n",
    "\n",
    "        df['Team1_Away'] = np.where((df['IDTeam1'] == df['WTeamID']) & (df['WLoc'] == -1), 1,\n",
    "                                np.where((df['IDTeam1'] == df['LTeamID']) & (df['WLoc'] == 1), 1, 0))\n",
    "        df['Team2_Away'] = np.where((df['IDTeam2'] == df['WTeamID']) & (df['WLoc'] == -1), 1,\n",
    "                                np.where((df['IDTeam2'] == df['LTeamID']) & (df['WLoc'] == 1), 1, 0))\n",
    "\n",
    "        df['Team1_Neutral'] = np.where((df['IDTeam1'] == df['WTeamID']) & (df['WLoc'] == 0), 1,\n",
    "                                   np.where((df['IDTeam1'] == df['LTeamID']) & (df['WLoc'] == 0), 1, 0))\n",
    "        df['Team2_Neutral'] = np.where((df['IDTeam2'] == df['WTeamID']) & (df['WLoc'] == 0), 1,\n",
    "                                   np.where((df['IDTeam2'] == df['LTeamID']) & (df['WLoc'] == 0), 1, 0))\n",
    "\n",
    "        # Drop the original WLoc column\n",
    "        df = df.drop(columns=['WLoc'])\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    def get_random_forest(self):\n",
    "      # Create the models here with the same parameters.\n",
    "      return RandomForestRegressor(\n",
    "          n_estimators=235,\n",
    "          random_state=42,\n",
    "          max_depth=5,\n",
    "          min_samples_split=2,\n",
    "          max_features='sqrt',\n",
    "          n_jobs=-1\n",
    "      )\n",
    "\n",
    "    def get_xbg(self):\n",
    "      return XGBRegressor(\n",
    "        max_depth=5,  \n",
    "        colsample_bytree=0.5, \n",
    "        subsample=0.8, \n",
    "        n_estimators=3000,  \n",
    "        learning_rate=0.1, \n",
    "        early_stopping_rounds=25,\n",
    "        objective='reg:logistic',\n",
    "        enable_categorical=True,\n",
    "        min_child_weight=5\n",
    "        #eval_metric= \"rmse\"\n",
    "      )\n",
    "    def scaled_data(self, input_data):\n",
    "        X_scaled = self.scaler.fit_transform(input_data)\n",
    "        return X_scaled\n",
    "    def impute_data(self, input_data):\n",
    "        X_imputed = self.imputer.fit_transform(input_data)\n",
    "        return X_imputed\n",
    "\n",
    "    def train_model(self, model, df):\n",
    "        X = df[self.col].reset_index(drop=True)#.fillna(-1)\n",
    "        y = df['Pred']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=100)\n",
    "        train_preds = model.predict(X_train).clip(0.001, 0.999)\n",
    "        test_preds0 = model.predict(X_test).clip(0.001, 0.999)\n",
    "\n",
    "        print(f'Log Loss (Train/Test): {log_loss(y_train, train_preds):.4f}, {log_loss(y_test, test_preds0):.4f}')\n",
    "        print(f'Brier Score (Train/Test): {brier_score_loss(y_train, train_preds):.4f}, {brier_score_loss(y_test, test_preds0):.4f}')\n",
    "        print(f'MSE (TrainTest): {mean_squared_error(y_train, train_preds):.4f}, {mean_squared_error(y_test, test_preds0):.4f}')\n",
    "\n",
    "        # Plot ROC Curve for the calibration set.\n",
    "        self.plot_roc_curve(y_test, test_preds0, \"Calibration Set ROC Curve\")\n",
    "\n",
    "        feature_importances = model.feature_importances_\n",
    "        feature_names = self.col\n",
    "        self.plot_feature_importance(feature_importances, feature_names)\n",
    "\n",
    "        self.plot_calibration_curve(y_test, test_preds0)\n",
    "\n",
    "        # Plot the distribution of calibrated predictions.\n",
    "        self.plot_prediction_distribution(y_test, \"Distribution of Test Predictions\")\n",
    "\n",
    "    def train_model_cv(self, model, df):\n",
    "        X = df[self.col].reset_index(drop=True)\n",
    "        y = df['Pred'].reset_index(drop=True)\n",
    "\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_mse_scores = []\n",
    "        cv_logloss_scores = []\n",
    "        cv_test_mse_scores = []\n",
    "        cv_test_logloss_scores = []\n",
    "        for train_index, val_index in kf.split(X):\n",
    "            X_train_cv, X_test_cv = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train_cv, y_test_cv = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "            # start with fresh model every time!\n",
    "            clonsed_model = clone(model)\n",
    "            clonsed_model.fit(X_train_cv, y_train_cv, eval_set=[(X_test_cv, y_test_cv)], verbose=100)\n",
    "            train_preds_cv = clonsed_model.predict(X_train_cv).clip(0.001, 0.999)\n",
    "            test_preds_cv = clonsed_model.predict(X_test_cv).clip(0.001, 0.999)\n",
    "\n",
    "\n",
    "            train_mse_cv = mean_squared_error(y_train_cv, train_preds_cv)\n",
    "            train_logloss_cv = log_loss(y_train_cv, train_preds_cv)\n",
    "            test_mse_cv = mean_squared_error(y_test_cv, test_preds_cv)\n",
    "            test_logloss_cv = log_loss(y_test_cv, test_preds_cv)\n",
    "\n",
    "            cv_mse_scores.append(train_mse_cv)\n",
    "            cv_logloss_scores.append(train_logloss_cv)\n",
    "            cv_test_mse_scores.append(test_mse_cv)\n",
    "            cv_test_logloss_scores.append(test_logloss_cv)\n",
    "\n",
    "        \n",
    "        print(f'Cross-validated MSE: {np.mean(cv_mse_scores):.4f},{np.mean(cv_test_mse_scores):.4f}')\n",
    "        print(f'Cross-validated LogLoss: {np.mean(cv_logloss_scores):.4f},{np.mean(cv_test_logloss_scores):.4f}')\n",
    "        print(\"Test cv array: \",cv_test_mse_scores)\n",
    "\n",
    "    def predict_submission(self, output_file='submission.csv'):\n",
    "        sub_X = self.sub[self.col].fillna(-1)\n",
    "        sub_X_imputed = self.imputer.transform(sub_X)\n",
    "        sub_X_scaled = self.scaler.transform(sub_X_imputed)\n",
    "\n",
    "        preds = self.model.predict(sub_X_scaled).clip(0.001, 0.999)\n",
    "        preds_calibrated = self.calibration_model.predict(preds.reshape(-1, 1)).clip(0.001, 0.999)\n",
    "\n",
    "        self.sub['Pred'] = preds_calibrated\n",
    "        self.sub[['ID', 'Pred']].to_csv(output_file, index=False)\n",
    "        print(f\"Submission file saved to {output_file}\")\n",
    "\n",
    "    def plot_feature_importance(self, importances, feature_names, top_n=20):\n",
    "        feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "        feature_importance_df = feature_importance_df.sort_values('importance', ascending=False).head(top_n)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x='importance', y='feature', data=feature_importance_df, palette='viridis')\n",
    "        plt.title('Top {} Feature Importances'.format(top_n))\n",
    "        plt.xlabel('Importance')\n",
    "        plt.ylabel('Feature')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_calibration_curve(self, y_true, y_proba, n_bins=10):\n",
    "\n",
    "        combined = np.stack([y_proba, y_true], axis=-1)\n",
    "        combined = combined[np.argsort(combined[:, 0])]\n",
    "        sorted_probas = combined[:, 0]\n",
    "        sorted_true = combined[:, 1]\n",
    "\n",
    "        bins = np.linspace(0, 1, n_bins + 1)\n",
    "        bin_midpoints = bins[:-1] + (bins[1] - bins[0]) / 2\n",
    "        bin_assignments = np.digitize(sorted_probas, bins) - 1\n",
    "\n",
    "        bin_sums = np.bincount(bin_assignments, weights=sorted_probas, minlength=n_bins)\n",
    "        bin_true = np.bincount(bin_assignments, weights=sorted_true, minlength=n_bins)\n",
    "        bin_total = np.bincount(bin_assignments, minlength=n_bins)\n",
    "\n",
    "        fraction_of_positives = bin_true / bin_total\n",
    "        fraction_of_positives[np.isnan(fraction_of_positives)] = 0\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(bin_midpoints, fraction_of_positives, marker='o', label='Calibration Curve')\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly Calibrated')\n",
    "\n",
    "        plt.xlabel('Predicted Probability')\n",
    "        plt.ylabel('Fraction of Positives')\n",
    "        plt.title('Calibration Curve')\n",
    "        plt.xlim(0, 1)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_prediction_distribution(self, predictions, title=\"Distribution of Predictions\"):\n",
    "        \"\"\"Plots the distribution of model predictions.\"\"\"\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.histplot(predictions, kde=True, color='skyblue')\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Predicted Probability')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_roc_curve(self, y_true, y_proba, title=\"ROC Curve\"):\n",
    "      \"\"\"Plots the Receiver Operating Characteristic (ROC) curve.\"\"\"\n",
    "      fpr, tpr, thresholds = roc_curve(y_true, y_proba)\n",
    "      roc_auc = auc(fpr, tpr)\n",
    "\n",
    "      plt.figure(figsize=(8, 6))\n",
    "      plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "      plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "      plt.xlabel('False Positive Rate')\n",
    "      plt.ylabel('True Positive Rate')\n",
    "      plt.title(title)\n",
    "      plt.xlim([0.0, 1.0])\n",
    "      plt.ylim([0.0, 1.05])\n",
    "      plt.legend(loc=\"lower right\")\n",
    "      plt.tight_layout()\n",
    "      plt.show()\n",
    "\n",
    "    def train_model_base_random_forest(self):\n",
    "        model = self.get_random_forest()\n",
    "        self.train_model_cv(model, self.games.fillna(-1))\n",
    "        self.train_model(model, self.games.fillna(-1))\n",
    "    \n",
    "    def train_model_base_xgboost(self):\n",
    "        model = self.get_xbg()\n",
    "        self.train_model_cv(model, self.games.fillna(-1))\n",
    "        self.train_model(model, self.games.fillna(-1))\n",
    "\n",
    "    def run_all(self):\n",
    "        self.load_data()\n",
    "        self.train_model()\n",
    "        self.predict_submission()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  only tournament data\n",
    "base (auc 0.81)\n",
    "Cross-validated MSE: 0.1447,0.1763\n",
    "Cross-validated LogLoss: 0.4481,0.5214\n",
    "Test cv array:  [0.17609657793288822, 0.17890084203209153, 0.18060527774749116, 0.16694279227517508, 0.1790824236025069]\n",
    "\n",
    "base + additional features (auc 0.82)\n",
    "Cross-validated MSE: 0.1441,0.1760\n",
    "Cross-validated LogLoss: 0.4470,0.5205\n",
    "Test cv array:  [0.176214665260042, 0.1760310657447056, 0.18180507612797978, 0.1668597346510348, 0.17891750344098578]\n",
    "\n",
    "\n",
    "base + additional features + sorted features (auc 0.82)\n",
    "    Cross-validated MSE: 0.1449,0.1758\n",
    "    Cross-validated LogLoss: 0.4489,0.5204\n",
    "    Test cv array:  [0.1759090613619681, 0.1767461997335639, 0.18180240042148935, 0.16652015296114905, 0.1780013603607607]\n",
    "\n",
    "    all data\n",
    "    Cross-validated MSE: 0.1817,0.2081\n",
    "    Cross-validated LogLoss: 0.5378,0.5972\n",
    "    Test cv array:  [0.2072069469355009, 0.20832444654169144, 0.2086487822469951, 0.20843162619147731, 0.20775880339858885]\n",
    "\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "papermill": {
     "duration": 79.711206,
     "end_time": "2025-02-20T05:14:16.779969",
     "exception": false,
     "start_time": "2025-02-20T05:12:57.068763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = TournamentPredictor(data_dir)\n",
    "predictor.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(\n",
    "        max_depth=5,  \n",
    "        colsample_bytree=0.5, \n",
    "        subsample=0.8, \n",
    "        n_estimators=3000,  \n",
    "        learning_rate=0.1, \n",
    "        early_stopping_rounds=50,\n",
    "        objective='reg:logistic',\n",
    "        enable_categorical=True,\n",
    "        min_child_weight=30\n",
    "        #eval_metric= \"rmse\"\n",
    "      )\n",
    "data = predictor.games.fillna(-1)\n",
    "predictor.train_model_cv(xgb, data)\n",
    "predictor.train_model(xgb, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11018643,
     "sourceId": 91497,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "leap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 86.992117,
   "end_time": "2025-02-20T05:14:17.825622",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-20T05:12:50.833505",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
